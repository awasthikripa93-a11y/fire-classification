{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awasthikripa93-a11y/fire-classification/blob/main/Copy_of_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        ":label:`sec_jupyter`\n",
        "\n",
        "\n",
        "This section describes how to edit and run the code\n",
        "in each section of this book\n",
        "using the Jupyter Notebook. Make sure you have\n",
        "installed Jupyter and downloaded the\n",
        "code as described in\n",
        ":ref:`chap_installation`.\n",
        "If you want to know more about Jupyter see the excellent tutorial in\n",
        "their [documentation](https://jupyter.readthedocs.io/en/latest/).\n",
        "\n",
        "\n",
        "## Editing and Running the Code Locally\n",
        "\n",
        "Suppose that the local path of the book's code is `xx/yy/d2l-en/`. Use the shell to change the directory to this path (`cd xx/yy/d2l-en`) and run the command `jupyter notebook`. If your browser does not do this automatically, open http://localhost:8888 and you will see the interface of Jupyter and all the folders containing the code of the book, as shown in :numref:`fig_jupyter00`.\n",
        "\n",
        "![The folders containing the code of this book.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter00.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter00`\n",
        "\n",
        "\n",
        "You can access the notebook files by clicking on the folder displayed on the webpage.\n",
        "They usually have the suffix \".ipynb\".\n",
        "For the sake of brevity, we create a temporary \"test.ipynb\" file.\n",
        "The content displayed after you click it is\n",
        "shown in :numref:`fig_jupyter01`.\n",
        "This notebook includes a markdown cell and a code cell. The content in the markdown cell includes \"This Is a Title\" and \"This is text.\".\n",
        "The code cell contains two lines of Python code.\n",
        "\n",
        "![Markdown and code cells in the \"text.ipynb\" file.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter01.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter01`\n",
        "\n",
        "\n",
        "Double click on the markdown cell to enter edit mode.\n",
        "Add a new text string \"Hello world.\" at the end of the cell, as shown in :numref:`fig_jupyter02`.\n",
        "\n",
        "![Edit the markdown cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter02.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter02`\n",
        "\n",
        "\n",
        "As demonstrated in :numref:`fig_jupyter03`,\n",
        "click \"Cell\" $\\rightarrow$ \"Run Cells\" in the menu bar to run the edited cell.\n",
        "\n",
        "![Run the cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter03.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter03`\n",
        "\n",
        "After running, the markdown cell is shown in :numref:`fig_jupyter04`.\n",
        "\n",
        "![The markdown cell after running.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter04.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter04`\n",
        "\n",
        "\n",
        "Next, click on the code cell. Multiply the elements by 2 after the last line of code, as shown in :numref:`fig_jupyter05`.\n",
        "\n",
        "![Edit the code cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter05.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter05`\n",
        "\n",
        "\n",
        "You can also run the cell with a shortcut (\"Ctrl + Enter\" by default) and obtain the output result from :numref:`fig_jupyter06`.\n",
        "\n",
        "![Run the code cell to obtain the output.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter06.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter06`\n",
        "\n",
        "\n",
        "When a notebook contains more cells, we can click \"Kernel\" $\\rightarrow$ \"Restart & Run All\" in the menu bar to run all the cells in the entire notebook. By clicking \"Help\" $\\rightarrow$ \"Edit Keyboard Shortcuts\" in the menu bar, you can edit the shortcuts according to your preferences.\n",
        "\n",
        "## Advanced Options\n",
        "\n",
        "Beyond local editing two things are quite important: editing the notebooks in the markdown format and running Jupyter remotely.\n",
        "The latter matters when we want to run the code on a faster server.\n",
        "The former matters since Jupyter's native ipynb format stores a lot of auxiliary data that is\n",
        "irrelevant to the content,\n",
        "mostly related to how and where the code is run.\n",
        "This is confusing for Git, making\n",
        "reviewing contributions very difficult.\n",
        "Fortunately there is an alternative---native editing in the markdown format.\n",
        "\n",
        "### Markdown Files in Jupyter\n",
        "\n",
        "If you wish to contribute to the content of this book, you need to modify the\n",
        "source file (md file, not ipynb file) on GitHub.\n",
        "Using the notedown plugin we\n",
        "can modify notebooks in the md format directly in Jupyter.\n",
        "\n",
        "\n",
        "First, install the notedown plugin, run the Jupyter Notebook, and load the plugin:\n",
        "\n",
        "```\n",
        "pip install d2l-notedown  # You may need to uninstall the original notedown.\n",
        "jupyter notebook --NotebookApp.contents_manager_class='notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "You may also turn on the notedown plugin by default whenever you run the Jupyter Notebook.\n",
        "First, generate a Jupyter Notebook configuration file (if it has already been generated, you can skip this step).\n",
        "\n",
        "```\n",
        "jupyter notebook --generate-config\n",
        "```\n",
        "\n",
        "Then, add the following line to the end of the Jupyter Notebook configuration file (for Linux or macOS, usually in the path `~/.jupyter/jupyter_notebook_config.py`):\n",
        "\n",
        "```\n",
        "c.NotebookApp.contents_manager_class = 'notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "After that, you only need to run the `jupyter notebook` command to turn on the notedown plugin by default.\n",
        "\n",
        "### Running Jupyter Notebooks on a Remote Server\n",
        "\n",
        "Sometimes, you may want to run Jupyter notebooks on a remote server and access it through a browser on your local computer. If Linux or macOS is installed on your local machine (Windows can also support this function through third-party software such as PuTTY), you can use port forwarding:\n",
        "\n",
        "```\n",
        "ssh myserver -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "The above string `myserver` is the address of the remote server.\n",
        "Then we can use http://localhost:8888 to access the remote server `myserver` that runs Jupyter notebooks. We will detail on how to run Jupyter notebooks on AWS instances\n",
        "later in this appendix.\n",
        "\n",
        "### Timing\n",
        "\n",
        "We can use the `ExecuteTime` plugin to time the execution of each code cell in Jupyter notebooks.\n",
        "Use the following commands to install the plugin:\n",
        "\n",
        "```\n",
        "pip install jupyter_contrib_nbextensions\n",
        "jupyter contrib nbextension install --user\n",
        "jupyter nbextension enable execute_time/ExecuteTime\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Using the Jupyter Notebook tool, we can edit, run, and contribute to each section of the book.\n",
        "* We can run Jupyter notebooks on remote servers using port forwarding.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Edit and run the code in this book with the Jupyter Notebook on your local machine.\n",
        "1. Edit and run the code in this book with the Jupyter Notebook *remotely* via port forwarding.\n",
        "1. Compare the running time of the operations $\\mathbf{A}^\\top \\mathbf{B}$ and $\\mathbf{A} \\mathbf{B}$ for two square matrices in $\\mathbb{R}^{1024 \\times 1024}$. Which one is faster?\n",
        "\n",
        "\n",
        "[Discussions](https://discuss.d2l.ai/t/421)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Import Libraries\n",
        "pip install numpy pandas matplotlib seaborn scikit-learn folium\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import  accuracy_score,classification_report,ConfusionMatrixDisplay\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "Load the dataset\n",
        "df1 = pd.read_csv('modis_2021_India.csv')\n",
        "df2 = pd.read_csv('modis_2022_India.csv')\n",
        "df3 = pd.read_csv('modis_2023_India.csv')\n",
        "df1.head() # print first 5 rows - df1.tail()\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tsatellite\tinstrument\tconfidence\tversion\tbright_t31\tfrp\tdaynight\ttype\n",
        "0\t28.0993\t96.9983\t303.0\t1.1\t1.1\t2021-01-01\t409\tTerra\tMODIS\t44\t6.03\t292.6\t8.6\tD\t0\n",
        "1\t30.0420\t79.6492\t301.8\t1.4\t1.2\t2021-01-01\t547\tTerra\tMODIS\t37\t6.03\t287.4\t9.0\tD\t0\n",
        "2\t30.0879\t78.8579\t300.2\t1.3\t1.1\t2021-01-01\t547\tTerra\tMODIS\t8\t6.03\t286.5\t5.4\tD\t0\n",
        "3\t30.0408\t80.0501\t302.0\t1.5\t1.2\t2021-01-01\t547\tTerra\tMODIS\t46\t6.03\t287.7\t10.7\tD\t0\n",
        "4\t30.6565\t78.9668\t300.9\t1.3\t1.1\t2021-01-01\t547\tTerra\tMODIS\t43\t6.03\t287.6\t9.0\tD\t0\n",
        "df2.head()\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tsatellite\tinstrument\tconfidence\tversion\tbright_t31\tfrp\tdaynight\ttype\n",
        "0\t30.1138\t80.0756\t300.0\t1.2\t1.1\t2022-01-01\t511\tTerra\tMODIS\t7\t6.03\t288.4\t7.1\tD\t0\n",
        "1\t23.7726\t86.2078\t306.1\t1.6\t1.2\t2022-01-01\t512\tTerra\tMODIS\t62\t6.03\t293.5\t10.4\tD\t2\n",
        "2\t22.2080\t84.8627\t304.8\t1.4\t1.2\t2022-01-01\t512\tTerra\tMODIS\t42\t6.03\t293.3\t5.8\tD\t2\n",
        "3\t23.7621\t86.3946\t306.9\t1.6\t1.2\t2022-01-01\t512\tTerra\tMODIS\t38\t6.03\t295.2\t9.3\tD\t2\n",
        "4\t23.6787\t86.0891\t303.6\t1.5\t1.2\t2022-01-01\t512\tTerra\tMODIS\t52\t6.03\t293.1\t7.2\tD\t2\n",
        "df3.head()\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tsatellite\tinstrument\tconfidence\tversion\tbright_t31\tfrp\tdaynight\ttype\n",
        "0\t9.3280\t77.6247\t318.0\t1.1\t1.0\t2023-01-01\t821\tAqua\tMODIS\t62\t61.03\t305.0\t7.6\tD\t0\n",
        "1\t10.4797\t77.9378\t313.8\t1.0\t1.0\t2023-01-01\t822\tAqua\tMODIS\t58\t61.03\t299.4\t4.3\tD\t0\n",
        "2\t13.2478\t77.2639\t314.7\t1.0\t1.0\t2023-01-01\t822\tAqua\tMODIS\t55\t61.03\t302.4\t4.9\tD\t0\n",
        "3\t12.2994\t78.4085\t314.3\t1.0\t1.0\t2023-01-01\t822\tAqua\tMODIS\t58\t61.03\t301.9\t4.8\tD\t0\n",
        "4\t14.1723\t75.5024\t338.4\t1.2\t1.1\t2023-01-01\t823\tAqua\tMODIS\t88\t61.03\n",
        "f = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "df.head()\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tsatellite\tinstrument\tconfidence\tversion\tbright_t31\tfrp\tdaynight\ttype\n",
        "0\t28.0993\t96.9983\t303.0\t1.1\t1.1\t2021-01-01\t409\tTerra\tMODIS\t44\t6.03\t292.6\t8.6\tD\t0\n",
        "1\t30.0420\t79.6492\t301.8\t1.4\t1.2\t2021-01-01\t547\tTerra\tMODIS\t37\t6.03\t287.4\t9.0\tD\t0\n",
        "2\t30.0879\t78.8579\t300.2\t1.3\t1.1\t2021-01-01\t547\tTerra\tMODIS\t8\t6.03\t286.5\t5.4\tD\t0\n",
        "3\t30.0408\t80.0501\t302.0\t1.5\t1.2\t2021-01-01\t547\tTerra\tMODIS\t46\t6.03\t287.7\t10.7\tD\t0\n",
        "4\t30.6565\t78.9668\t300.9\t1.3\t1.1\t2021-01-01\t547\tTerra\tMODIS\t43\t6.03\t287.6\t9.0\tD\t0\n",
        "df.shape # rows and cols\n",
        "(271217, 15)\n",
        "df.info() # dt, memc\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 271217 entries, 0 to 271216\n",
        "Data columns (total 15 columns):\n",
        " #   Column      Non-Null Count   Dtype\n",
        "---  ------      --------------   -----\n",
        " 0   latitude    271217 non-null  float64\n",
        " 1   longitude   271217 non-null  float64\n",
        " 2   brightness  271217 non-null  float64\n",
        " 3   scan        271217 non-null  float64\n",
        " 4   track       271217 non-null  float64\n",
        " 5   acq_date    271217 non-null  object\n",
        " 6   acq_time    271217 non-null  int64\n",
        " 7   satellite   271217 non-null  object\n",
        " 8   instrument  271217 non-null  object\n",
        " 9   confidence  271217 non-null  int64\n",
        " 10  version     271217 non-null  float64\n",
        " 11  bright_t31  271217 non-null  float64\n",
        " 12  frp         271217 non-null  float64\n",
        " 13  daynight    271217 non-null  object\n",
        " 14  type        271217 non-null  int64\n",
        "dtypes: float64(8), int64(3), object(4)\n",
        "memory usage: 31.0+ MB\n",
        "# Any missing values?\n",
        "df.isnull().sum()\n",
        "latitude      0\n",
        "longitude     0\n",
        "brightness    0\n",
        "scan          0\n",
        "track         0\n",
        "acq_date      0\n",
        "acq_time      0\n",
        "satellite     0\n",
        "instrument    0\n",
        "confidence    0\n",
        "version       0\n",
        "bright_t31    0\n",
        "frp           0\n",
        "daynight      0\n",
        "type          0\n",
        "dtype: int64\n",
        "df.duplicated().sum()\n",
        "0\n",
        "# List out column names to check\n",
        "df.columns\n",
        "Index(['latitude', 'longitude', 'brightness', 'scan', 'track', 'acq_date',\n",
        "       'acq_time', 'satellite', 'instrument', 'confidence', 'version',\n",
        "       'bright_t31', 'frp', 'daynight', 'type'],\n",
        "      dtype='object')\n",
        "df.describe().T # statistics of dataset - numbers!\n",
        "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
        "latitude\t271217.0\t23.947505\t4.919846\t8.1362\t20.9655\t23.7888\t27.7827\t34.9734\n",
        "longitude\t271217.0\t81.284024\t6.559071\t68.4526\t75.8802\t79.3209\t84.7559\t97.1044\n",
        "brightness\t271217.0\t323.719192\t14.147221\t300.0000\t314.5000\t322.0000\t330.7000\t505.7000\n",
        "scan\t271217.0\t1.421732\t0.630742\t1.0000\t1.0000\t1.2000\t1.5000\t4.8000\n",
        "track\t271217.0\t1.152716\t0.201943\t1.0000\t1.0000\t1.1000\t1.2000\t2.0000\n",
        "acq_time\t271217.0\t824.623755\t353.966965\t321.0000\t648.0000\t756.0000\t825.0000\t2202.0000\n",
        "confidence\t271217.0\t64.065081\t18.165329\t0.0000\t54.0000\t66.0000\t76.0000\t100.0000\n",
        "version\t271217.0\t21.933778\t24.935515\t6.0300\t6.0300\t6.0300\t61.0300\t61.0300\n",
        "bright_t31\t271217.0\t303.499177\t8.282440\t267.2000\t298.2000\t302.5000\t309.2000\t400.1000\n",
        "frp\t271217.0\t27.722058\t81.017471\t0.0000\t8.7000\t13.5000\t24.5000\t6961.8000\n",
        "type\t271217.0\t0.100385\t0.437215\t0.0000\t0.0000\t0.0000\t0.0000\t3.0000\n",
        "# Check Unique values of target variable\n",
        "df.type.value_counts()\n",
        "0    257625\n",
        "2     13550\n",
        "3        42\n",
        "Name: type, dtype: int64\n",
        "Exploratory Data Analysis (EDA)\n",
        "# Check unique and n unique for all categorical features\n",
        "for col in df.columns:\n",
        "  if df[col].dtype == 'object':\n",
        "    print(f\"Column: {col}\")\n",
        "    print(f\"Unique values: {df[col].unique()}\")\n",
        "    print(f\"Number of unique values: {df[col].nunique()}\")\n",
        "    print(\"-\" * 50)\n",
        "Column: acq_date\n",
        "Unique values: ['2021-01-01' '2021-01-02' '2021-01-03' ... '2023-12-29' '2023-12-30'\n",
        " '2023-12-31']\n",
        "Number of unique values: 1088\n",
        "--------------------------------------------------\n",
        "Column: satellite\n",
        "Unique values: ['Terra' 'Aqua']\n",
        "Number of unique values: 2\n",
        "--------------------------------------------------\n",
        "Column: instrument\n",
        "Unique values: ['MODIS']\n",
        "Number of unique values: 1\n",
        "--------------------------------------------------\n",
        "Column: daynight\n",
        "Unique values: ['D' 'N']\n",
        "Number of unique values: 2\n",
        "--------------------------------------------------\n",
        "# Count plot for 'type'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='type', data=df)\n",
        "plt.title('Distribution of Fire Types')\n",
        "plt.xlabel('Fire Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "The count plot shows the distribution of different fire types in the dataset.\n",
        "It is evident that 'MODIS' is the most frequent fire type, followed by 'VIIRS'.\n",
        "The 'type' variable appears to be unbalanced, with 'MODIS' having significantly more observations than 'VIIRS'. This imbalance might need to be considered during model training.\n",
        "# Histogram of 'confidence'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['confidence'], bins=20, kde=True)\n",
        "plt.title('Distribution of Confidence')\n",
        "plt.xlabel('Confidence')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "The histogram illustrates the distribution of the 'confidence' feature.\n",
        "The distribution appears to be bimodal, with peaks around low confidence values and high confidence values.\n",
        "There are fewer observations in the middle range of confidence.\n",
        "This suggests that observations are often recorded with either low confidence or high confidence.\n",
        "# Box plot for 'confidence' by 'type'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='type', y='confidence', data=df)\n",
        "plt.title('Confidence by Fire Type')\n",
        "plt.xlabel('Fire Type')\n",
        "plt.ylabel('Confidence')\n",
        "plt.show()\n",
        "\n",
        "The box plot shows the distribution of 'confidence' for each fire type\n",
        "Both 0 and 2 have a wide range of confidence values.\n",
        "The median confidence for both types appears to be in the higher range.\n",
        "There are some outliers, particularly for the 'MODIS' type, indicating observations with unusually low or high confidence.\n",
        "# Scatter plot of 'latitude' vs 'longitude'\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='longitude', y='latitude', data=df, hue='type', s=10)\n",
        "plt.title('Fire Locations by Type')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend(title='Fire Type')\n",
        "plt.show()\n",
        "\n",
        "The scatter plot visualizes the geographical distribution of fire locations, colored by fire type.\n",
        "It provides a visual representation of where fires are occurring based on latitude and longitude.\n",
        "Different fire types might be concentrated in specific geographical areas, which could be a useful feature for modeling.\n",
        "The density of points indicates areas with higher fire activity.\n",
        "# Count plot for 'daynight'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='daynight', data=df)\n",
        "plt.title('Distribution of Day/Night Observations')\n",
        "plt.xlabel('Day/Night')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "The count plot for 'daynight' shows whether the fire observations were made during the day or night.\n",
        "It indicates the proportion of day versus night observations in the dataset.\n",
        "Knowing the distribution of day/night observations can be relevant as detection capabilities or fire behavior might differ between day and night.\n",
        "# Count plot for 'Satellite'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='satellite', data=df)\n",
        "plt.title('Distribution of Satellite Observations')\n",
        "plt.xlabel('Satellite')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "This count plot shows the distribution of observations made by different satellites.\n",
        "It reveals which satellites contributed the most data to the dataset.\n",
        "Understanding the satellite distribution can be important as different satellites may have different characteristics or coverage.\n",
        "# Count plot for 'version'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='version', data=df)\n",
        "plt.title('Distribution of Version')\n",
        "plt.xlabel('Version')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "#this code take more time\n",
        "#Pairplot for numerical features (subset)\n",
        "#sns.pairplot(df[['latitude', 'longitude', 'brightness', 'confidence', 'frp', 'type']], hue='type', diag_kind='kde')\n",
        "#plt.suptitle('Pairplot of Numerical Features')\n",
        "#plt.show()\n",
        "The pairplot provides a matrix of scatter plots for all pairs of numerical features and histograms/KDE plots on the diagonal for each feature, separated by the 'type' variable. Here are some insights from the pairplot:\n",
        "\n",
        "Individual Feature Distributions (Diagonal): The diagonal plots (histograms/KDEs) show the distribution of each numerical feature for each fire type.\n",
        "\n",
        "latitude and longitude: These show the geographical distribution, reinforcing the scatter plot observation. Different fire types appear to be concentrated in certain geographical areas.\n",
        "brightness: The distribution of brightness values can be compared between fire types. There might be differences in the typical brightness of fires detected by MODIS versus VIIRS.\n",
        "confidence: This shows the distribution of confidence for each type, similar to the earlier box plot but as a histogram/KDE. It can highlight differences in the confidence levels associated with each fire type.\n",
        "frp: The distribution of fire radiative power (FRP) can be compared. This might reveal if one fire type tends to have significantly higher or lower FRP values than the other.\n",
        "Relationships Between Features (Off-Diagonal Scatter Plots): The off-diagonal scatter plots show the relationship between pairs of numerical features, colored by fire type.\n",
        "\n",
        "latitude vs. longitude: As seen before, this visualizes the geographical distribution by type.\n",
        "brightness vs. confidence: This plot shows the relationship between brightness and confidence. Is there a correlation? Does higher brightness tend to correlate with higher confidence? How does this relationship differ between fire types?\n",
        "brightness vs. frp: This shows the relationship between brightness and fire radiative power. These two features are likely related. The plot can reveal the strength and nature of this relationship and whether it varies by fire type.\n",
        "confidence vs. frp: This visualizes the relationship between confidence and FRP. Does higher FRP tend to result in higher confidence? How does this relationship differ for different fire types?\n",
        "Other pairs: Examine the relationships between latitude/longitude and the other numerical features (brightness, confidence, frp). Are there geographical patterns in these features?\n",
        "# Heatmap of correlations between numerical features\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df[['latitude', 'longitude', 'brightness', 'confidence', 'frp']].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()\n",
        "\n",
        "The heatmap visualizes the Pearson correlation coefficients between the numerical features: 'latitude', 'longitude', 'brightness', 'confidence', and 'frp'. The values range from -1 to 1, where:\n",
        "\n",
        "1 indicates a perfect positive linear correlation.\n",
        "-1 indicates a perfect negative linear correlation.\n",
        "0 indicates no linear correlation.\n",
        "The color intensity and the annotation (annot=True) help in quickly identifying the strength and direction of the relationships.\n",
        "Key insights from the heatmap:\n",
        "\n",
        "High Correlation between brightness and frp: There appears to be a strong positive correlation between 'brightness' and 'frp'. This is expected as both features are related to the intensity of the fire. Higher brightness is likely to be associated with higher fire radiative power. This strong correlation might indicate multicollinearity if both features are used directly in a linear model, but can also be insightful for understanding the data.\n",
        "\n",
        "Moderate Correlation between brightness and confidence: There seems to be a moderate positive correlation between 'brightness' and 'confidence'. This suggests that brighter fire detections tend to be associated with higher confidence levels.\n",
        "\n",
        "Moderate Correlation between frp and confidence: Similarly, there is likely a moderate positive correlation between 'frp' and 'confidence'. Fires with higher radiative power might be easier to detect and thus have higher confidence scores.\n",
        "\n",
        "Low Correlation with Geographical Features: The correlations between 'latitude' and 'longitude' with 'brightness', 'confidence', and 'frp' appear to be relatively low. This suggests that the intensity or confidence of a fire detection is not strongly linearly related to its geographical location. While there might be spatial patterns as seen in the scatter plot, a simple linear correlation doesn't capture them strongly.\n",
        "\n",
        "Correlation between latitude and longitude: The correlation between 'latitude' and 'longitude' is often low unless there's a specific geographical pattern in the data that aligns linearly. In this case, it's likely low, indicating that fires are distributed across various locations without a strong linear relationship between their latitude and longitude coordinates within the dataset.\n",
        "\n",
        "Overall, the heatmap provides a concise overview of the linear relationships between the numerical features. It highlights the expected strong correlations between features related to fire intensity (brightness, frp, confidence) and shows that geographical coordinates have weaker linear relationships with these intensity measures. This information can be valuable for feature selection, understanding feature interactions, and guiding the choice of modeling techniques.\n",
        "\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns\n",
        "numerical_cols\n",
        "Index(['latitude', 'longitude', 'brightness', 'scan', 'track', 'acq_time',\n",
        "       'confidence', 'version', 'bright_t31', 'frp', 'type'],\n",
        "      dtype='object')\n",
        "numerical_cols = ['brightness', 'scan', 'track', 'acq_time','confidence', 'version', 'bright_t31', 'frp']\n",
        "df[numerical_cols].hist(bins=50, figsize=(15, 10))\n",
        "plt.suptitle('Histograms of Numerical Features')\n",
        "plt.show()\n",
        "\n",
        "'brightness': The distribution of brightness values. This shows the range of detected fire brightness and where the values tend to cluster. It might reveal if fires tend to be of low, medium, or high brightness.\n",
        "'scan': The distribution of scan sizes. This feature relates to the size of the pixel footprint. The histogram shows the typical scan sizes in the dataset.\n",
        "'track': Similar to scan, this relates to the track size. The histogram shows the distribution of track sizes.\n",
        "'acq_time': The distribution of acquisition times (likely represented as a numerical value like time of day). This histogram can reveal patterns in when fires are detected (e.g., more detections during certain hours).\n",
        "'confidence': The distribution of confidence scores. This is a numerical representation of the earlier confidence histogram and box plot. It reinforces the bimodal nature observed earlier.\n",
        "'version': The distribution of different version values. This shows the frequency of observations from different processing versions.\n",
        "'bright_t31': The distribution of brightness temperature at band 31. This is another measure related to fire intensity. Its distribution can be compared to 'brightness'.\n",
        "'frp': The distribution of fire radiative power. This shows the typical FRP values in the dataset and their range. It complements the 'brightness' histogram in understanding fire intensity.\n",
        "'type': While 'type' is included in the numerical columns list due to its representation, its histogram will show the distribution of the encoded numerical values for fire types. This visually confirms the class imbalance seen in the count plot.\n",
        "-Overall, these histograms provide a detailed look at the individual distributions of the numerical features. They help in understanding the range, central tendency, and variability of each feature, identifying potential outliers, and assessing the shape of the distribution (e.g., normal, skewed, bimodal). This information is crucial for data preprocessing, feature understanding, and selecting appropriate modeling techniques.\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "\n",
        "# List of numerical features to check for distribution\n",
        "numerical_features = ['brightness', 'confidence', 'frp', 'bright_t31', 'scan', 'track']\n",
        "\n",
        "for feature in numerical_features:\n",
        "    print(f\"Analyzing distribution for: {feature}\")\n",
        "\n",
        "    # KDE Plot\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.kdeplot(df[feature], fill=True)\n",
        "    plt.title(f'KDE Plot of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "\n",
        "    # QQ Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    stats.probplot(df[feature], dist=\"norm\", plot=plt)\n",
        "    plt.title(f'QQ Plot of {feature}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"-\" * 50)\n",
        "Analyzing distribution for: brightness\n",
        "\n",
        "--------------------------------------------------\n",
        "Analyzing distribution for: confidence\n",
        "\n",
        "--------------------------------------------------\n",
        "Analyzing distribution for: frp\n",
        "\n",
        "--------------------------------------------------\n",
        "Analyzing distribution for: bright_t31\n",
        "\n",
        "--------------------------------------------------\n",
        "Analyzing distribution for: scan\n",
        "\n",
        "--------------------------------------------------\n",
        "Analyzing distribution for: track\n",
        "\n",
        "--------------------------------------------------\n",
        "'brightness': Distribution is skewed and bimodal, QQ plot shows significant deviation from normality.\n",
        "\n",
        "'confidence': Distribution is bimodal with peaks at low and high values, QQ plot confirms non-normality, especially in the tails.\n",
        "\n",
        "'frp': Distribution is highly skewed to the right, QQ plot shows a strong departure from the normal distribution, particularly for larger values.\n",
        "\n",
        "'bright_t31': Distribution appears somewhat skewed, QQ plot indicates deviation from normality, especially at the extremes.\n",
        "\n",
        "'scan': Distribution is concentrated at lower values with a tail towards higher values, QQ plot suggests non-normality.\n",
        "\n",
        "'track': Distribution is concentrated at lower values with a tail towards higher values, QQ plot suggests non-normality.\n",
        "\n",
        "# --- Temporal Analysis ---\n",
        "# Convert 'acq_date' to datetime objects\n",
        "df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
        "# Extract temporal features\n",
        "df['year'] = df['acq_date'].dt.year\n",
        "df['month'] = df['acq_date'].dt.month\n",
        "df['day_of_week'] = df['acq_date'].dt.dayofweek # Monday=0, Sunday=6\n",
        "df['day_of_year'] = df['acq_date'].dt.dayofyear\n",
        "df['hour'] = df['acq_time'].astype(str).str[:2].astype(int) # Assuming acq_time is HHMM\n",
        "Extracting Temporal Features: It converts the acq_date column to datetime objects and extracts new features like year, month, day_of_week, day_of_year, and hour from the acquisition date and time.\n",
        "Visualizing Temporal Distributions: It generates count plots to show:\n",
        "The number of fire detections per month.\n",
        "The number of fire detections per day of the week.\n",
        "# Visualize fire detections over months\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='month', palette='viridis')\n",
        "plt.title('Fire Detections by Month (2023)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Detections')\n",
        "plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.show()\n",
        "/var/folders/tx/wk7wgjjj50l10ddtt3kczpnh0000gn/T/ipykernel_46389/3766763484.py:3: FutureWarning:\n",
        "\n",
        "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
        "\n",
        "  sns.countplot(data=df, x='month', palette='viridis')\n",
        "\n",
        "# Visualize fire detections by day of the week\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='day_of_week', palette='viridis')\n",
        "plt.title('Fire Detections by Day of Week (2023)')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Detections')\n",
        "plt.xticks(ticks=range(7), labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
        "plt.show()\n",
        "/var/folders/tx/wk7wgjjj50l10ddtt3kczpnh0000gn/T/ipykernel_46389/714612371.py:3: FutureWarning:\n",
        "\n",
        "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
        "sns.countplot(data=df, x='day_of_week', palette='viridis')\n",
        "\n",
        "Outliers and Outlier Treatments\n",
        "Outliers: Outliers are data points that are significantly different from other observations in a dataset. They can occur due to measurement errors, data entry mistakes, or genuinely rare events. Outliers can skew statistical analyses (like mean, standard deviation) and impact the performance of machine learning models.\n",
        "\n",
        "# Visualize outliers using box plots for key numerical features\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df[numerical_cols])\n",
        "plt.title('Box Plots for Key Numerical Features')\n",
        "plt.ylabel('Value')\n",
        "plt.show()\n",
        "'brightness', 'bright_t31', 'frp': These fire intensity-related features show a wide range and numerous high-value outliers, suggesting that while most fires might have moderate intensity, there are instances of very bright or high-FRP fires. The lower whiskers might also show some outliers on the lower end.\n",
        "\n",
        "'scan', 'track': These features related to pixel size also show outliers, indicating observations where the scan/track size was significantly different from the typical values.\n",
        "\n",
        "'confidence': The box plot for confidence, similar to the histogram, likely reinforces the concentration of data at the ends (low and high confidence), with some outliers in the middle range or beyond.\n",
        "\n",
        "'acq_time': Depending on how 'acq_time' is represented numerically, the box plot could show if there are acquisition times that are significantly different from the usual patterns.\n",
        "\n",
        "'version', 'type': These are likely represented numerically but are essentially categorical or ordinal. Their box plots might not be as informative as count plots for distribution, but they can still show the spread of other numerical features within each version/type category if plotted against them.\n",
        "\n",
        "def remove_outliers_iqr(df, column):\n",
        "  Q1 = df[column].quantile(0.25)\n",
        "  Q3 = df[column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  df_cleaned = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)].copy()\n",
        "  return df_cleaned\n",
        "\n",
        "# Apply outlier removal to numerical columns\n",
        "for col in numerical_cols:\n",
        "  df = remove_outliers_iqr(df, col)\n",
        "\n",
        "print(\"Shape after removing outliers:\", df.shape)\n",
        "Shape after removing outliers: (189370, 20)\n",
        "# Visualize box plots after outlier removal\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df[numerical_cols])\n",
        "plt.title('Box Plots for Numerical Features After Outlier Removal')\n",
        "plt.ylabel('Value')\n",
        "plt.show()\n",
        "\n",
        "Box Plots (After):\n",
        "\n",
        "The individual outlier points above and below the whiskers in the previous box plots have been significantly reduced or eliminated for the treated columns ('brightness', 'scan', 'track', 'bright_t31', 'frp').\n",
        "The maximum and minimum values represented by the upper and lower whiskers will be much closer to the bulk of the data, as extreme values have been removed.\n",
        "The scale of the y-axis in the box plots for the treated features is likely smaller, as it now focuses on the data within the calculated IQR range.\n",
        "The boxes (IQR) and whiskers now represent the distribution of the majority of the cleaned data. While the IQR method removes values outside 1.5IQR from the quartiles, some data points beyond the whiskers might still be present, but they represent the less extreme values within the filtered dataset. The visual spread of the central 50% (the box) and the range covered by the whiskers (typically 1.5IQR) will be more representative of the data after removing the most extreme values.\n",
        "For 'confidence', 'acq_time', 'version', and 'type', where outlier removal wasn't explicitly applied in the code snippet, their box plots would show similar distributions as before, potentially still displaying outliers if present in the original data.\n",
        "df.head()\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tsatellite\tinstrument\tconfidence\tversion\tbright_t31\tfrp\tdaynight\ttype\tyear\tmonth\tday_of_week\tday_of_year\thour\n",
        "0\t28.0993\t96.9983\t303.0\t1.1\t1.1\t2021-01-01\t409\tTerra\tMODIS\t44\t6.03\t292.6\t8.6\tD\t0\t2021\t1\t4\t1\t40\n",
        "1\t30.0420\t79.6492\t301.8\t1.4\t1.2\t2021-01-01\t547\tTerra\tMODIS\t37\t6.03\t287.4\t9.0\tD\t0\t2021\t1\t4\t1\t54\n",
        "3\t30.0408\t80.0501\t302.0\t1.5\t1.2\t2021-01-01\t547\tTerra\tMODIS\t46\t6.03\t287.7\t10.7\tD\t0\t2021\t1\t4\t1\t54\n",
        "4\t30.6565\t78.9668\t300.9\t1.3\t1.1\t2021-01-01\t547\tTerra\tMODIS\t43\t6.03\t287.6\t9.0\tD\t0\t2021\t1\t4\t1\t54\n",
        "6\t31.4366\t76.8988\t300.5\t1.0\t1.0\t2021-01-01\t547\tTerra\tMODIS\t36\t6.03\t287.2\t5.3\tD\t0\t2021\t1\t4\t1\t54\n",
        "df.type.value_counts()\n",
        "0    182841\n",
        "2      6501\n",
        "3        28\n",
        "Name: type, dtype: int64\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "categorical_cols\n",
        "Index(['satellite', 'instrument', 'daynight'], dtype='object')\n",
        "# Select categorical columns for encoding\n",
        "categorical_cols_to_encode = ['daynight', 'satellite', 'instrument']\n",
        "\n",
        "# Apply One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols_to_encode, drop_first=True)\n",
        "df_encoded.head(100)\n",
        "latitude\tlongitude\tbrightness\tscan\ttrack\tacq_date\tacq_time\tconfidence\tversion\tbright_t31\tfrp\ttype\tyear\tmonth\tday_of_week\tday_of_year\thour\tsatellite_Terra\n",
        "0\t28.0993\t96.9983\t303.0\t1.1\t1.1\t2021-01-01\t409\t44\t6.03\t292.6\t8.6\t0\t2021\t1\t4\t1\t40\t1\n",
        "1\t30.0420\t79.6492\t301.8\t1.4\t1.2\t2021-01-01\t547\t37\t6.03\t287.4\t9.0\t0\t2021\t1\t4\t1\t54\t1\n",
        "3\t30.0408\t80.0501\t302.0\t1.5\t1.2\t2021-01-01\t547\t46\t6.03\t287.7\t10.7\t0\t2021\t1\t4\t1\t54\t1\n",
        "4\t30.6565\t78.9668\t300.9\t1.3\t1.1\t2021-01-01\t547\t43\t6.03\t287.6\t9.0\t0\t2021\t1\t4\t1\t54\t1\n",
        "6\t31.4366\t76.8988\t300.5\t1.0\t1.0\t2021-01-01\t547\t36\t6.03\t287.2\t5.3\t0\t2021\t1\t4\t1\t54\t1\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "116\t23.7766\t86.3997\t313.8\t1.0\t1.0\t2021-01-02\t454\t51\t6.03\t300.9\t6.8\t2\t2021\t1\t5\t2\t45\t1\n",
        "117\t23.6829\t86.0831\t310.4\t1.1\t1.0\t2021-01-02\t454\t61\t6.03\t297.3\t6.2\t2\t2021\t1\t5\t2\t45\t1\n",
        "118\t23.6661\t86.9215\t308.2\t1.0\t1.0\t2021-01-02\t454\t50\t6.03\t297.4\t4.8\t2\t2021\t1\t5\t2\t45\t1\n",
        "119\t23.8059\t86.3222\t313.5\t1.0\t1.0\t2021-01-02\t454\t66\t6.03\t300.9\t8.1\t0\t2021\t1\t5\t2\t45\t1\n",
        "120\t23.8448\t84.9512\t310.7\t1.2\t1.1\t2021-01-02\t454\t68\t6.03\t297.7\t8.5\t0\t2021\t1\t5\t2\t45\t1\n",
        "100 rows Ã— 18 columns\n",
        "\n",
        "df_encoded.type.value_counts()\n",
        "0    182841\n",
        "2      6501\n",
        "3        28\n",
        "Name: type, dtype: int64\n",
        "pip install folium - if needed use this\n",
        "# !pip install folium\n",
        "import folium\n",
        "\n",
        "# Create map and sample data\n",
        "india_map = folium.Map(location=[22.351115, 78.667743], zoom_start=5)\n",
        "sample_df = df_encoded.sample(n=min(10000, len(df_encoded)), random_state=42)\n",
        "\n",
        "# Add markers\n",
        "for _, row in sample_df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row['latitude'], row['longitude']],\n",
        "        radius=3,\n",
        "        color='red',\n",
        "        fill=True,\n",
        "        fill_opacity=0.6,\n",
        "        popup=f\"FRP: {row['frp']:.2f}, Date: {row['acq_date'].strftime('%Y-%m-%d')}\"\n",
        "    ).add_to(india_map)\n",
        "\n",
        "display(india_map)\n",
        "Make this Notebook Trusted to load map: File -> Trust Notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iOeaY0TlcATj",
        "outputId": "cf7ce932-15e1-45a0-9453-66ce2958b884"
      },
      "id": "iOeaY0TlcATj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (ipython-input-1-3901379664.py, line 24)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-3901379664.py\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    0\t28.0993\t96.9983\t303.0\t1.1\t1.1\t2021-01-01\t409\tTerra\tMODIS\t44\t6.03\t292.6\t8.6\tD\t0\u001b[0m\n\u001b[0m     \t       \t       \t     \t   \t   \t     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}